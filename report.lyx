#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble

\author{Chris Swetenham (s1149322)}
\title{Peer-to-Peer Human-Robot Interaction in Collaborative Tasks}
\date{November 9, 2011}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Collaborative Problem Solving in Human-Robot Interaction
\end_layout

\begin_layout Author
Chris Swetenham (s1149322)
\end_layout

\begin_layout Date
First Draft - 1st Jan 2012
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% Gestures, facial expressions, natural language, physical interaction/touch
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Recognising and exhibiting emotions, intention
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Learning and respecting social convention
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Mixed-initiative interaction - not fixed turns in conversation
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Conversation, speech recognition and generation, natural language processing
 and generation.
 Generating referring expressions
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Nasa robonaut
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Modelling what the other can see and giving and understanding references
 to objects in their frame of reference
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Safety
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% Online games for evaluating and learning, data collection
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Collaborative Problem Solving is a multidisciplinary problem in Human-Robot
 Interaction which brings together much of the current work in robotics,
 natural language, human-computer interaction, and artificial intelligence.
 Human and robot participants must be able to understand each other without
 impediment to the task, must understand each other's roles and intentions
 in the task, and must agree on steps to be performed to complete the task.
 The robots must also be careful not to take actions which might endanger
 the human participants.
\end_layout

\begin_layout Standard
Human-Agent Interaction is an extension of Human-Computer Interaction to
 interactions with software that exhibits some form of agency, potentially
 embodied and situated in a virtual world.
 Human-Robot Interaction is an extension of Human-Agent Interaction to interacti
ons with embodied, situated agents in the physical world.
 TODO gives a survey of the field of Human-Robot Interaction.
\end_layout

\begin_layout Standard
Social Robotics studies robots which interact by social means with humans
 and each other, including gestures, facial expressions and speech.
 TODO gives a survey of Social Robotics.
\end_layout

\begin_layout Standard
Human-Robot Collaboration studies social interaction between humans and
 robots in the context of a shared task to be performed.
 TODO gives a survey of Human-Robot Collaboration.
\end_layout

\begin_layout Standard
When performing a task, humans have many simultaneous modes of interaction:
 speech, facial expressions and stances, gaze direction, gestures, direct
 physical contact.
 These may serve several purposes: to convey intention or emotion, to direct
 the other participant's actions or attention, or to directly execute a
 step in the plan for the task.
 For example, a pointing gesture could direct the other participant's attention
 to a tool or area, or it could tell them to move themselves to the location
 pointed to.
 Extending an arm holding an object towards the other participants signals
 the intention to hand over the object while also being the first step of
 the execution of this intention.
 It may be be necessary to consider multiple modes at once to understand
 the overall meaning.
\end_layout

\begin_layout Standard
In this report we will cover several projects in the area of collaborative
 problem-solving in human-robot interaction between a single robot and single
 human participant.
 We will in particular focus on approaches to natural language generation,
 intention recognition and the use natural conversation in shared planning
 and execution of a task.
\end_layout

\begin_layout Section
TODO
\end_layout

\begin_layout Standard
In terms of communication from the robot to the human, the Leonardo project
\begin_inset CommandInset citation
LatexCommand cite
key "Breazeal2004"

\end_inset

 focuses on an expressive robot capable of many facial and body gestures
 and without any natural language generation or speech synthesis capabilites.
\end_layout

\begin_layout Standard
In terms of working on a shared task, the Leonardo project focuses on the
 human teaching the robot how to participate in a task.
 The idea is that active tutelage can be much more effective than relying
 on blind experimentation by the robot or complex, brittle a priori knowledge
 in getting the robot to perform a new task.
\end_layout

\begin_layout Standard
Joint Intention refers to the state of affairs where several participants
 share a common goal and a common plan for achieving that goal.
 In the Leonardo project, the human participant sets the goal and teaches
 the robot the steps required.
 In the JAST project, the robot participant sets the goal and teaches the
 human the steps required.
\end_layout

\begin_layout Standard
Natural Language Generation is the counterpart of Natural Language Processing.
 It refers to the production of human text or speech from some internal
 data structure specific to the agent.
 In the context of this review the most important aspects are communicating
 the actions to be performed and the objects they should be performed on.
 In fact, generating descriptions of objects and their location is easy;
 the difficult part is deciding which information to include or not in the
 description.
 If there is not enough information, the description can be ambiguous or
 confusing for the human listener; if the information is too specific, it
 may seem to the listener as though the extra information was included for
 a specific reason even if it is irrelevant to the task.
\end_layout

\begin_layout Standard
Speech output can be accompanied by facial expressions or gestures, such
 as looking at and/or pointing to the object being referenced.
 This an example of 
\emph on
multimodal interaction
\emph default
.
 In the JAST project, the generation of referring expressions and the use
 of gestures were both studied and evaluated for their effectiveness in
 communicating with the human participant.
 In the Leonardo project, speech output was avoided entirely in favour of
 an expressive body and facial design.
\end_layout

\begin_layout Standard
Another aspect of communication in cooperative problem-solving, again expressibl
e and recognisable through both speech and gesture, is the meta-level dialogue
 indicating agreement or disagreement with the other participant, and understand
ing or not understanding the other participant.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Projects:
\end_layout

\begin_layout Plain Layout
Lino->iCat
\end_layout

\begin_layout Plain Layout
iCat + AC -> JAST -> JAMES
\end_layout

\begin_layout Plain Layout
Kismet -> Leonardo
\end_layout

\begin_layout Plain Layout
INDIGO
\end_layout

\begin_layout Plain Layout
Paro
\end_layout

\begin_layout Plain Layout
Robonaut -> Robonaut 2
\end_layout

\begin_layout Plain Layout
Build core of lit review around the software architectures used in each
 project? And maybe some various strategies for error-handling, etc scenarios?
\end_layout

\begin_layout Plain Layout
GIVE challenge: can give history of entries, strategies, performance
\end_layout

\begin_layout Plain Layout
Areas: intention, nlg, cps
\end_layout

\begin_layout Standard
Intro: describe the general task and some of the projects covered.
\end_layout

\begin_layout Plain Layout
Talk about 
\begin_inset Quotes eld
\end_inset

joint intention theory
\begin_inset Quotes erd
\end_inset

?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "References/IRR"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
